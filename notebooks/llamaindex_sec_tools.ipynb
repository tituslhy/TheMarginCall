{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "import warnings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "warnings.filterwarnings('ignore')\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    Document\n",
    ")\n",
    "from llama_index.core.tools.tool_spec.base import BaseToolSpec\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor\n",
    "\n",
    "from sec_api import QueryApi\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from llamaindex_config import llm, embed_model, text_splitter\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = llm\n",
    "embed_model = embed_model\n",
    "text_splitter = text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from llama_index.core.bridge.pydantic import Field, PrivateAttr\n",
    "from llama_index.core.schema import MetadataMode, NodeWithScore, QueryBundle, TextNode\n",
    "import torch\n",
    "\n",
    "DEFAULT_INSTRUCTION_STR = \"Given the context, please answer the final question\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class LLMLinguaPostProcessor2(LongLLMLinguaPostprocessor):\n",
    "    \"\"\"Optimization of nodes.\n",
    "\n",
    "    Compress using LongLLMLingua2 paper.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    metadata_mode: MetadataMode = Field(\n",
    "        default=MetadataMode.ALL, description=\"Metadata mode.\"\n",
    "    )\n",
    "    instruction_str: str = Field(\n",
    "        default=DEFAULT_INSTRUCTION_STR, description=\"Instruction string.\"\n",
    "    )\n",
    "    target_token: int = Field(\n",
    "        default=300, description=\"Target number of compressed tokens.\"\n",
    "    )\n",
    "    rank_method: str = Field(default=\"longllmlingua\", description=\"Ranking method.\")\n",
    "    additional_compress_kwargs: Dict[str, Any] = Field(\n",
    "        default_factory=dict, description=\"Additional compress kwargs.\"\n",
    "    )\n",
    "\n",
    "    _llm_lingua: Any = PrivateAttr()\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\",\n",
    "        device_map: str = device,\n",
    "        model_config: Optional[dict] = {},\n",
    "        open_api_config: Optional[dict] = {},\n",
    "        metadata_mode: MetadataMode = MetadataMode.ALL,\n",
    "        instruction_str: str = DEFAULT_INSTRUCTION_STR,\n",
    "        target_token: int = 500,\n",
    "        rank_method: str = \"longllmlingua\",\n",
    "        additional_compress_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    ):\n",
    "        \"\"\"LongLLMLingua Compressor for Node Context.\"\"\"\n",
    "        from llmlingua import PromptCompressor\n",
    "\n",
    "        open_api_config = open_api_config or {}\n",
    "        additional_compress_kwargs = additional_compress_kwargs or {}\n",
    "\n",
    "        if model_name != \"microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\":\n",
    "            use_llmlingua2 = False\n",
    "            model_config = {\"revision\": \"main\"}\n",
    "        else:\n",
    "            use_llmlingua2 = True\n",
    "        \n",
    "        self._llm_lingua = PromptCompressor(\n",
    "            model_name=model_name,\n",
    "            device_map=device_map,\n",
    "            model_config=model_config,\n",
    "            open_api_config=open_api_config,\n",
    "            use_llmlingua2 = use_llmlingua2,\n",
    "        )\n",
    "        super().__init__(\n",
    "            metadata_mode=metadata_mode,\n",
    "            instruction_str=instruction_str,\n",
    "            target_token=target_token,\n",
    "            rank_method=rank_method,\n",
    "            additional_compress_kwargs=additional_compress_kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SECTool(BaseToolSpec):\n",
    "    \"\"\"Tools to read SEC10K reports\"\"\"\n",
    "    \n",
    "    spec_functions=[\n",
    "        \"search_10q_10k\",\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, \n",
    "                 sec_api_key = os.getenv('SEC_API_KEY'),\n",
    "                 cohere_api_key = os.getenv('COHERE_API_KEY')\n",
    "                 ):\n",
    "        \"\"\"Initialize SEC tool\"\"\"\n",
    "        self.sec_api_key = sec_api_key\n",
    "        self.cohere_api_key = cohere_api_key\n",
    "        if self.sec_api_key is None:\n",
    "            raise ValueError(\"SEC API key cannot be none\")\n",
    "        if self.cohere_api_key is None:\n",
    "            raise ValueError(\"Cohere API key cannot be none\")\n",
    "        self.queryApi = QueryApi(api_key=self.sec_api_key)\n",
    "        self.reranker = CohereRerank(top_n = 4, api_key = self.cohere_api_key)\n",
    "        self.prompt_compressor = LongLLMLinguaPostprocessor(\n",
    "            instruction_str = \"Given the context, please answer the final question\",\n",
    "            target_token = 300,\n",
    "            rank_method = \"longllmlingua\",\n",
    "            additional_compress_kwargs = {\n",
    "                \"condition_compare\": True,\n",
    "                \"condition_in_question\": \"after\",\n",
    "                \"context_budget\": \"+100\",\n",
    "                \"reorder_context\": \"sort\", #enables document reorder\n",
    "                \"dynamic_context_compression_ratio\": 0.3,\n",
    "            },\n",
    "            model_name = \"gpt2\"\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def _download_form_html(url: str):\n",
    "        headers = {\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Accept-Language': 'en-US,en;q=0.9,pt-BR;q=0.8,pt;q=0.7',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "            'Dnt': '1',\n",
    "            'Sec-Ch-Ua': '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\"',\n",
    "            'Sec-Ch-Ua-Mobile': '?0',\n",
    "            'Sec-Ch-Ua-Platform': '\"macOS\"',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        return response.text\n",
    "    \n",
    "    def get_retriever_from_url(self, url: str, embed_model=embed_model):   \n",
    "        \"\"\"Creates an in-memory retriever from a URL\"\"\"\n",
    "        text = self._download_form_html(url=url)\n",
    "        soup = BeautifulSoup(text, 'html.parser')\n",
    "        texts = soup.get_text()\n",
    "        nodes = text_splitter.get_nodes_from_documents([Document(text=texts)])\n",
    "        return VectorStoreIndex(nodes, embed_model=embed_model).as_retriever(\n",
    "            similarity_top_k = 10\n",
    "        )\n",
    "    \n",
    "    def return_contexts(self, url: str, question: str):\n",
    "        \"\"\"Retrieves and reranks nodes given a query string and a url \n",
    "        from an in-memory vector index\"\"\"\n",
    "        retriever = self.get_retriever_from_url(url = url)\n",
    "        nodes = retriever.retrieve(question)\n",
    "        reranked_nodes = self.reranker.postprocess_nodes(\n",
    "            nodes = nodes,\n",
    "            query_str = question)\n",
    "        refined_nodes = self.prompt_compressor.postprocess_nodes(\n",
    "            nodes = reranked_nodes,\n",
    "            query_str = question\n",
    "        )\n",
    "        return \"\\n\\n\".join([n.get_content() for n in refined_nodes])\n",
    "    \n",
    "    def search_10q_10k(\n",
    "        self, \n",
    "        ticker: str, \n",
    "        question: str,\n",
    "        tenq: bool = True):\n",
    "        \"\"\"\n",
    "        Useful to search information from the latest 10-Q or 10-K forms of a\n",
    "        given stock.\n",
    "        args:\n",
    "            ticker (str): ticker of interest\n",
    "            query (str): the question of interest\n",
    "            tenq (bool): Whether or not to search the 10-Q form\n",
    "\n",
    "        \"\"\"\n",
    "        if tenq is True:\n",
    "            query = {\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": f\"ticker:{ticker} AND formType:\\\"10-Q\\\"\"\n",
    "                    }\n",
    "                },\n",
    "                \"from\": \"0\",\n",
    "                \"size\": \"1\",\n",
    "                \"sort\": [{ \"filedAt\": { \"order\": \"desc\" }}]\n",
    "            }\n",
    "        else:\n",
    "            query = {\n",
    "            \"query\": {\n",
    "                \"query_string\": {\n",
    "                \"query\": f\"ticker:{ticker} AND formType:\\\"10-K\\\"\"\n",
    "                }\n",
    "            },\n",
    "            \"from\": \"0\",\n",
    "            \"size\": \"1\",\n",
    "            \"sort\": [{ \"filedAt\": { \"order\": \"desc\" }}]\n",
    "            }\n",
    "        filings = self.queryApi.get_filings(query)['filings']\n",
    "        if len(filings) == 0:\n",
    "            return \"Sorry I couldn't find any filing for this stock, check if ticker is correct\"\n",
    "        link = filings[0]['linkToFilingDetails']\n",
    "        return self.return_contexts(url=link, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f9905dea9840b8a9e6baa89d7dbb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "secTool = SECTool()\n",
    "SECToolList = secTool.to_tool_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import (\n",
    "    FunctionCallingAgentWorker,\n",
    "    AgentRunner\n",
    ")\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tools = SECToolList,\n",
    "    llm = llm,\n",
    "    verbose = True)\n",
    "agent = AgentRunner(agent_worker=agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What are the risks that Illumina faces?\n",
      "=== Calling Function ===\n",
      "Calling function: search_10q_10k with args: {\"ticker\": \"ILMN\", \"question\": \"What are the risks that Illumina faces?\", \"tenq\": true}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Function Output ===\n",
      "On 20, we action the Court EC Div. The Decision, any order decision the FTC any other or to which Illumina is required to GRAIL (an FTC Decision), and-app applicable and our have imposed in the and future significant additional on legal, financial, other additional may in loss other on condition operations Such effects could include divIL terms that materially which weIL., we not or financial suchment which result in negative consequences. For we to be G sale and so would tax received and tax in ( basis is and $ million In will likely inparty contracts agreements including contingent rightsthe) us as of the may unable to discharge with divest, and divestiture. extent that the following a divest, may more estimating the future liabilities anyVR G., G may be by such which the The Divment Decision to that G has to to5 of operations- We expect funding1, from G’s sheet Inter Measures, the Order Div an FTC Div Decision other order any governmental or-app the applicable have in the and could may also management� and from existing other opportunities any or, material have and price We cannot predict what adverse consequences our, or complete, and business. July, the European decision finding the EU Regulation its, acquiring exert and Commission reviewthe 14 European a EU ofapproximately432  provided in 20 payment Commission’ictional fine accrued the the andor authorities may We of additional or, other condition and results of operations.\n",
      "=== LLM Response ===\n",
      "Based on the information from Illumina's 10-Q filings, some of the key risks that Illumina faces include:\n",
      "\n",
      "1. Regulatory risks: Illumina faces significant regulatory risks related to its proposed acquisition of GRAIL. The FTC has filed an administrative complaint to block the acquisition, and Illumina may be required to divest GRAIL or face other significant legal, financial, and operational consequences if the acquisition is not approved. This could have material negative impacts on Illumina's business.\n",
      "\n",
      "2. Financial and operational impacts: A divestiture of GRAIL or other adverse regulatory outcomes could result in significant financial and operational challenges for Illumina, including loss of revenue, tax implications, and disruption to existing contracts and agreements.\n",
      "\n",
      "3. Uncertainty and unpredictability: Illumina is unable to predict the full extent of the adverse consequences it may face from regulatory actions related to the GRAIL acquisition. This uncertainty poses a significant risk to the company's future business and financial performance.\n",
      "\n",
      "4. Potential fines and penalties: Illumina may face additional fines or penalties from regulatory authorities in the U.S. and Europe related to the GRAIL acquisition, further straining the company's financial position.\n",
      "\n",
      "In summary, the key risks center around the regulatory challenges Illumina faces with the GRAIL acquisition, which could have wide-ranging negative impacts on the company's finances, operations, and overall business outlook.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Based on the information from Illumina's 10-Q filings, some of the key risks that Illumina faces include:\n",
       "\n",
       "1. Regulatory risks: Illumina faces significant regulatory risks related to its proposed acquisition of GRAIL. The FTC has filed an administrative complaint to block the acquisition, and Illumina may be required to divest GRAIL or face other significant legal, financial, and operational consequences if the acquisition is not approved. This could have material negative impacts on Illumina's business.\n",
       "\n",
       "2. Financial and operational impacts: A divestiture of GRAIL or other adverse regulatory outcomes could result in significant financial and operational challenges for Illumina, including loss of revenue, tax implications, and disruption to existing contracts and agreements.\n",
       "\n",
       "3. Uncertainty and unpredictability: Illumina is unable to predict the full extent of the adverse consequences it may face from regulatory actions related to the GRAIL acquisition. This uncertainty poses a significant risk to the company's future business and financial performance.\n",
       "\n",
       "4. Potential fines and penalties: Illumina may face additional fines or penalties from regulatory authorities in the U.S. and Europe related to the GRAIL acquisition, further straining the company's financial position.\n",
       "\n",
       "In summary, the key risks center around the regulatory challenges Illumina faces with the GRAIL acquisition, which could have wide-ranging negative impacts on the company's finances, operations, and overall business outlook.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What are the risks that Illumina faces?\"\n",
    "response = agent.chat(query)\n",
    "\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt compression works and latency is improved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../tools/sec_tools.py\n",
    "\n",
    "#%%\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    Document\n",
    ")\n",
    "from llama_index.core.tools.tool_spec.base import BaseToolSpec\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor\n",
    "\n",
    "from sec_api import QueryApi\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "__curdir__ = os.getcwd()\n",
    "\n",
    "if \"tools\" in __curdir__:\n",
    "    sys.path.append(os.path.join(\n",
    "        __curdir__,\n",
    "        \"../src\"\n",
    "    ))\n",
    "else:\n",
    "    sys.path.append(\"./src\")\n",
    "\n",
    "from llamaindex_config import llm, embed_model, text_splitter\n",
    "\n",
    "llm = llm\n",
    "embed_model = embed_model\n",
    "text_splitter = text_splitter\n",
    "#%%\n",
    "class SECTool(BaseToolSpec):\n",
    "    \"\"\"Tools to read SEC10K reports\"\"\"\n",
    "    \n",
    "    spec_functions=[\n",
    "        \"search_10q_10k\",\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, \n",
    "                 sec_api_key = os.getenv('SEC_API_KEY'),\n",
    "                 cohere_api_key = os.getenv('COHERE_API_KEY')\n",
    "                 ):\n",
    "        \"\"\"Initialize SEC tool\"\"\"\n",
    "        self.sec_api_key = sec_api_key\n",
    "        self.cohere_api_key = cohere_api_key\n",
    "        if self.sec_api_key is None:\n",
    "            raise ValueError(\"SEC API key cannot be none\")\n",
    "        if self.cohere_api_key is None:\n",
    "            raise ValueError(\"Cohere API key cannot be none\")\n",
    "        self.queryApi = QueryApi(api_key=self.sec_api_key)\n",
    "        self.reranker = CohereRerank(top_n = 4, api_key = self.cohere_api_key)\n",
    "        self.prompt_compressor = LongLLMLinguaPostprocessor(\n",
    "            instruction_str = \"Given the context, please answer the final question\",\n",
    "            target_token = 300,\n",
    "            rank_method = \"longllmlingua\",\n",
    "            additional_compress_kwargs = {\n",
    "                \"condition_compare\": True,\n",
    "                \"condition_in_question\": \"after\",\n",
    "                \"context_budget\": \"+100\",\n",
    "                \"reorder_context\": \"sort\", #enables document reorder\n",
    "                \"dynamic_context_compression_ratio\": 0.3,\n",
    "            },\n",
    "            model_name = \"gpt2\"\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _download_form_html(url: str):\n",
    "        \"\"\"Function to download text from SEC website\"\"\"\n",
    "        headers = {\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Accept-Language': 'en-US,en;q=0.9,pt-BR;q=0.8,pt;q=0.7',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "            'Dnt': '1',\n",
    "            'Sec-Ch-Ua': '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\"',\n",
    "            'Sec-Ch-Ua-Mobile': '?0',\n",
    "            'Sec-Ch-Ua-Platform': '\"macOS\"',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        return response.text\n",
    "    \n",
    "    def get_retriever_from_url(self, url: str, embed_model=embed_model):   \n",
    "        \"\"\"Creates an in-memory retriever from a URL\"\"\"\n",
    "        text = self._download_form_html(url=url)\n",
    "        soup = BeautifulSoup(text, 'html.parser')\n",
    "        texts = soup.get_text()\n",
    "        nodes = text_splitter.get_nodes_from_documents([Document(text=texts)])\n",
    "        return VectorStoreIndex(nodes, embed_model=embed_model).as_retriever(\n",
    "            similarity_top_k = 10\n",
    "        )\n",
    "    \n",
    "    def return_contexts(self, url: str, question: str):\n",
    "        \"\"\"Retrieves and reranks nodes given a query string and a url \n",
    "        from an in-memory vector index\"\"\"\n",
    "        retriever = self.get_retriever_from_url(url = url)\n",
    "        nodes = retriever.retrieve(question)\n",
    "        reranked_nodes = self.reranker.postprocess_nodes(\n",
    "            nodes = nodes,\n",
    "            query_str = question)\n",
    "        refined_nodes = self.prompt_compressor.postprocess_nodes(\n",
    "            nodes = reranked_nodes,\n",
    "            query_str = question\n",
    "        )\n",
    "        return \"\\n\\n\".join([n.get_content() for n in refined_nodes])\n",
    "    \n",
    "    def search_10q_10k(\n",
    "        self, \n",
    "        ticker: str, \n",
    "        question: str,\n",
    "        tenq: bool = True):\n",
    "        \"\"\"\n",
    "        Useful to search information from the latest 10-Q or 10-K forms of a\n",
    "        given stock.\n",
    "        args:\n",
    "            ticker (str): ticker of interest\n",
    "            query (str): the question of interest\n",
    "            tenq (bool): Whether or not to search the 10-Q form\n",
    "        \"\"\"\n",
    "        if tenq is True:\n",
    "            query = {\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": f\"ticker:{ticker} AND formType:\\\"10-Q\\\"\"\n",
    "                    }\n",
    "                },\n",
    "                \"from\": \"0\",\n",
    "                \"size\": \"1\",\n",
    "                \"sort\": [{ \"filedAt\": { \"order\": \"desc\" }}]\n",
    "            }\n",
    "        else:\n",
    "            query = {\n",
    "            \"query\": {\n",
    "                \"query_string\": {\n",
    "                \"query\": f\"ticker:{ticker} AND formType:\\\"10-K\\\"\"\n",
    "                }\n",
    "            },\n",
    "            \"from\": \"0\",\n",
    "            \"size\": \"1\",\n",
    "            \"sort\": [{ \"filedAt\": { \"order\": \"desc\" }}]\n",
    "            }\n",
    "        filings = self.queryApi.get_filings(query)['filings']\n",
    "        if len(filings) == 0:\n",
    "            return \"Sorry I couldn't find any filing for this stock, check if ticker is correct\"\n",
    "        link = filings[0]['linkToFilingDetails']\n",
    "        return self.return_contexts(url=link, question=question)\n",
    "\n",
    "def get_sec_tool():\n",
    "    \"\"\"Return SEC tool powered by SEC Edgar Filings API\"\"\"\n",
    "    secTool = SECTool()\n",
    "    return secTool.to_tool_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
